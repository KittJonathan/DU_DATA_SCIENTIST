{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3ea14-8c22-44ad-8227-bda5a2713f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import logistic\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import sech\n",
    "\n",
    "# Parameters and sample size\n",
    "N = 10**5  # Number of samples\n",
    "lambda_param = 1  # Parameter value for the CDF and PDF\n",
    "\n",
    "# Step 1: Generate uniform random probabilities and transform them\n",
    "p_k = np.random.uniform(0, 1, N)\n",
    "x_k = np.log(p_k / (1 - p_k))  # Apply inverse CDF transformation for lambda=1\n",
    "\n",
    "# Plot histogram of x_k\n",
    "plt.hist(x_k, bins=100, density=True, alpha=0.6, color='skyblue', edgecolor='black', label=\"Generated Sample Density\")\n",
    "\n",
    "# Step 2: Define the PDF and overlay it\n",
    "def logistic_pdf(x, lambda_param=1):\n",
    "    return (lambda_param / 4) * sech(lambda_param * x / 2)**2\n",
    "\n",
    "x_vals = np.linspace(-10, 10, 1000)\n",
    "pdf_vals = logistic_pdf(x_vals, lambda_param)\n",
    "\n",
    "# Plot the theoretical PDF on top of the histogram\n",
    "plt.plot(x_vals, pdf_vals, color='red', lw=2, label=\"Theoretical PDF $f_x(x; \\\\lambda=1)$\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Histogram of Generated Sample with Theoretical PDF Overlay\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Maximum Likelihood Estimation (MLE) for lambda\n",
    "def neg_log_likelihood(lambda_val, x_k):\n",
    "    if lambda_val <= 0:  # To ensure positive lambda\n",
    "        return np.inf\n",
    "    pdf_vals = (lambda_val / 4) * sech(lambda_val * x_k / 2)**2\n",
    "    return -np.sum(np.log(pdf_vals))\n",
    "\n",
    "# Minimize negative log-likelihood\n",
    "result = minimize(neg_log_likelihood, x0=1, args=(x_k), method='L-BFGS-B', bounds=[(0.01, None)])\n",
    "lambda_hat = result.x[0]\n",
    "print(f\"Estimated λ (MLE): {lambda_hat}\")\n",
    "\n",
    "# Step 4: Estimate uncertainty in lambda using graphical method\n",
    "lambda_range = np.linspace(lambda_hat - 0.5, lambda_hat + 0.5, 100)\n",
    "nll_vals = [neg_log_likelihood(lam, x_k) for lam in lambda_range]\n",
    "\n",
    "# Find the uncertainty where NLL increases by 0.5 from minimum\n",
    "min_nll = min(nll_vals)\n",
    "lambda_plus = lambda_range[np.where(nll_vals >= min_nll + 0.5)[0][0]]\n",
    "lambda_minus = lambda_range[np.where(nll_vals >= min_nll + 0.5)[0][-1]]\n",
    "lambda_uncertainty = (lambda_plus - lambda_minus) / 2\n",
    "print(f\"λ ± Uncertainty: {lambda_hat} ± {lambda_uncertainty}\")\n",
    "\n",
    "# Step 5: Generate logistic sample using scipy and compare\n",
    "scipy_sample = logistic.rvs(size=N)\n",
    "\n",
    "# Plot residuals histogram\n",
    "bins = np.linspace(-10, 10, 100)\n",
    "hist_my_sample, _ = np.histogram(x_k, bins=bins, density=True)\n",
    "hist_scipy_sample, _ = np.histogram(scipy_sample, bins=bins, density=True)\n",
    "bin_centers = (bins[1:] + bins[:-1]) / 2\n",
    "residuals = (hist_my_sample - hist_scipy_sample) / np.sqrt(hist_my_sample + 1e-6)  # Approximate uncertainty\n",
    "\n",
    "plt.bar(bin_centers, residuals, width=0.2, color='purple', alpha=0.6, label=\"Residuals\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residuals Histogram between Generated Sample and Scipy Logistic Sample\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Standardize x_k to create z_k and estimate pi using variance\n",
    "mu_x = np.mean(x_k)\n",
    "var_x = np.var(x_k)\n",
    "z_k = (x_k - mu_x) / np.sqrt(3 * var_x)\n",
    "\n",
    "# Repeat MLE for the rescaled variable z_k\n",
    "result_z = minimize(neg_log_likelihood, x0=1, args=(z_k), method='L-BFGS-B', bounds=[(0.01, None)])\n",
    "lambda_hat_z = result_z.x[0]\n",
    "print(f\"Estimated λ for z (MLE): {lambda_hat_z}\")\n",
    "\n",
    "# Graphical uncertainty estimation for λ_hat_z\n",
    "nll_vals_z = [neg_log_likelihood(lam, z_k) for lam in lambda_range]\n",
    "min_nll_z = min(nll_vals_z)\n",
    "lambda_plus_z = lambda_range[np.where(nll_vals_z >= min_nll_z + 0.5)[0][0]]\n",
    "lambda_minus_z = lambda_range[np.where(nll_vals_z >= min_nll_z + 0.5)[0][-1]]\n",
    "lambda_uncertainty_z = (lambda_plus_z - lambda_minus_z) / 2\n",
    "print(f\"λ for z ± Uncertainty: {lambda_hat_z} ± {lambda_uncertainty_z}\")\n",
    "\n",
    "# Final conclusion on compatibility with π\n",
    "print(f\"Estimated π-compatible λ for z: {lambda_hat_z} ± {lambda_uncertainty_z}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
